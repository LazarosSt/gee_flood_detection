{"cells":[{"cell_type":"markdown","metadata":{"id":"5oeEOfZWPFsB"},"source":["# **1) Import the Modules**\n","\n","Modules are code libraries that contain a set of ready-to-use functions.\n","\n","* The `ee` module allows developers to interact with Google Earth Engine using the Python programming language.\n","* The `os` module provides functions to perform tasks such as file and directory operations, process management, and environment variable manipulation.\n","* The `datetime` module supplies classes for manipulating dates and times.\n","* The `tabulate` module allows the user to display data in a table format.\n","* The `google.colab` module provides access to some of the unique features and functionality of Google Colab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wwhxmo80nTC2"},"outputs":[],"source":["import ee\n","import os\n","import datetime\n","import tabulate\n","\n","from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"lGa1REK31H2j"},"source":["# **2) Authentication Procedure**\n","\n","This section provides instructions for setting up the Google Earth Engine Python API on Colab and for setting up Google Drive on Colab. These steps should be performed each time you start/restart/rollback a Colab session."]},{"cell_type":"markdown","metadata":{"id":"M1dE1vTqTaq7"},"source":["## **2.1) GEE**\n","\n","The `ee.Authenticate` function authenticates access to the Google Earth Engine servers, while the `ee.Initialize` function initializes it. After executing the following cell, the user is prompted to grant Google Earth Engine access to their Google account.\n","\n","**Note:** The Earth Engine API is installed by default in Google Colaboratory."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48103,"status":"ok","timestamp":1699862362085,"user":{"displayName":"lazaros stam","userId":"13443305908766428871"},"user_tz":-120},"id":"bJFUmXltHtWy","outputId":"bdcbba84-d33d-46a0-b7ca-6b71ef8dd6bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n","\n","    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=udcDvPyV3xbh3Ju9ra6Nk7Cm6u7I41YnV0lHperWAJU&tc=6VTh0nDOJDoQ9mefXif0gDyv7e9ZJCORPpiLDdGkBqk&cc=8fT7HxeYKPCrbSDuki67QttnmnKWU19RFz95yEpkg80\n","\n","The authorization workflow will generate a code, which you should paste in the box below.\n","Enter verification code: 4/1AfJohXmIVqv1W-e11r3HmK_PzNpdqcWA3eAlU_mi_lP3dwDnTpBvM-BXbwA\n","\n","Successfully saved authorization token.\n"]},{"name":"stderr","output_type":"stream","text":["*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_doiqkQG3NJ1t8IS?source=API\n"]}],"source":["ee.Authenticate()\n","ee.Initialize(project=\"...\")"]},{"cell_type":"markdown","metadata":{"id":"k48w_jWcntia"},"source":["## **2.2) GD**\n","\n","The `drive.mount` function allows access to specific folders of Google Drive. Granting access to Google Drive allows code running in the notebook to modify files in Google Drive.\n","\n","**Note:** When using the `Mount Drive` button in the file browser, no authentication codes are required for notebooks edited only by the current user."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23337,"status":"ok","timestamp":1699862386232,"user":{"displayName":"lazaros stam","userId":"13443305908766428871"},"user_tz":-120},"id":"B-jZK-dxOpUb","outputId":"62705ba7-e1fd-48ca-860b-39adb6d9a3e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["drive.mount(\"/content/gdrive\")"]},{"cell_type":"markdown","metadata":{"id":"GZBfbabwvRri"},"source":["# **3) Functions**"]},{"cell_type":"markdown","metadata":{"id":"0mUnhj_D-UwP"},"source":["Data Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_RxRbxIKRLZ"},"outputs":[],"source":["def relative_property_importance(key, value):\n","  \"\"\"\n","  Description:\n","    Calculates the relative importance of a property based on its value.\n","\n","  Parameters:\n","    key: The property key.\n","    value: The property value.\n","\n","  Returns:\n","    The relative importance value.\n","  \"\"\"\n","  return ee.Number(value).divide(importancesSum).multiply(100)\n","\n","\n","def export_tasks_viewer(exportTasksIds, tableFormat: str = \"plain\"):\n","  \"\"\"\n","  Description:\n","    Displays a table view which contains useful information about the provided export tasks.\n","\n","  Notes:\n","    * Task_Id: The task identifier.\n","    * Task_State: One of READY, RUNNING, COMPLETED, FAILED, CANCELLED, UNSUBMITTED or UNKNOWN.\n","    * Task_Type: One of EXPORT_IMAGE, EXPORT_TILES, EXPORT_FEATURES, EXPORT_VIDEO.\n","    * Task_Attempt: Number of attempts.\n","    * Task_Description: A human-readable description of the task.\n","    * Queue_Time: The time that is taken while being in a queue.\n","    * Execution_Time: The time spent by the servers executing the task.\n","    * Completion_Time: SUm of queue and execution times.\n","    * Error_Message: Failure reason. Appears only if state is FAILED. May also include other fields.\n","\n","  Arguments:\n","    exportTasksIdsList (list) (mandatory) A list of export task identifiers.\n","    tableFormat (str) (optional) The table format to use. Defaults to \"plain\".\n","\n","  Returns:\n","    None, displays the export tasks table.\n","  \"\"\"\n","  taskInfo = []\n","  tableHeaders = [\n","    \"Task_Id\", \"Task_State\", \"Task_Type\", \"Task_Attempt\", \"Task_Description\",\n","    \"Queue_Time\", \"Execution_Time\", \"Completion_Time\", \"Error_Message\"\n","  ]\n","  tableFormats = tabulate._table_formats.keys()\n","\n","  if tableFormat not in tableFormats:\n","    raise ValueError(f\"Invalid table format. Choose from: `{tableFormats}`.\")\n","\n","  # Populate taskInfo.\n","  for exportTaskId in exportTasksIds:\n","\n","    taskState = ee.data.getTaskStatus(exportTaskId)[0][\"state\"]\n","    taskType = ee.data.getTaskStatus(exportTaskId)[0][\"task_type\"]\n","    taskDescription = ee.data.getTaskStatus(exportTaskId)[0][\"description\"]\n","    startTimestamp = datetime.datetime.fromtimestamp(ee.data.getTaskStatus(exportTaskId)[0][\"start_timestamp_ms\"]/1000.0)\n","    updateTimestamp = datetime.datetime.fromtimestamp(ee.data.getTaskStatus(exportTaskId)[0][\"update_timestamp_ms\"]/1000.0)\n","    creationTimestamp = datetime.datetime.fromtimestamp(ee.data.getTaskStatus(exportTaskId)[0][\"creation_timestamp_ms\"]/1000.0)\n","\n","    queueTime = None\n","    taskAttempt = None\n","    executionTime = None\n","    completionTime = None\n","\n","    if taskState not in [\"READY\", \"RUNNING\"]:\n","      queueTime = (startTimestamp - creationTimestamp).total_seconds()\n","      executionTime = (updateTimestamp - startTimestamp).total_seconds()\n","\n","    if taskState == \"COMPLETED\":\n","      taskAttempt = ee.data.getTaskStatus(exportTaskId)[0][\"attempt\"]\n","      completionTime = (updateTimestamp - creationTimestamp).total_seconds()\n","\n","    try:\n","      errorMessage = ee.data.getTaskStatus(exportTaskId)[0][\"error_message\"]\n","    except KeyError:\n","      errorMessage = None  # This just means that the export task has not failed.\n","\n","    taskInfo.append([exportTaskId, taskState, taskType, taskAttempt, taskDescription, queueTime, executionTime, completionTime, errorMessage])\n","\n","  # Table display.\n","  table = tabulate.tabulate(taskInfo, headers=tableHeaders, tablefmt=tableFormat)\n","  print(table)"]},{"cell_type":"markdown","metadata":{"id":"jVJ6z_8Q9p2x"},"source":["# **4) Parameters**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEfWGx4rTGIi"},"outputs":[],"source":["nonWaterSampleIdentifiers =  [\n","  \"...\"\n","]\n","\n","floodSampleIdentifiers = [\n","    \"...\"\n","]\n","\n","waterSampleIdentifiers = [\n","  \"...\"\n","]"]},{"cell_type":"markdown","metadata":{"id":"cVQwmP-0JWq5"},"source":["Cart"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7DOFXzG0JTcf"},"outputs":[],"source":["classifierParameters = {\n","  \"maxNodes\": null,\n","  \"minLeafPopulation\": 1\n","}\n","\n","classifierFeatures = [\n","  \"VHVHD\", \"VHVHQ\", \"VVVHD\", \"VVVHQ\", \"VVVVD\", \"VVVVQ\", \"NDPID\", \"NDPIQ\",\n","  \"PRE_VV\", \"PRE_VH\", \"PRE_NDPI\", \"POST_VV\", \"POST_VH\", \"POST_NDPI\"\n","]\n","\n","# GD paths.\n","classifierIdentifier = \"cart\"\n","destinationPath = \"...\""]},{"cell_type":"markdown","metadata":{"id":"vDOAc02MJX8F"},"source":["Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L64Tli1GJTeV"},"outputs":[],"source":["classifierParameters = {\n","  \"numberOfTrees\": 25,\n","  # \"variablesPerSplit\": 3,\n","  # \"minLeafPopulation\": 5,\n","  # \"bagFraction\": 0.5,\n","  # \"maxNodes\": None,\n","  \"seed\": 0\n","}\n","\n","classifierFeatures = [\n","  \"VHVHD\", \"VHVHQ\", \"VVVHD\", \"VVVHQ\", \"VVVVD\", \"VVVVQ\", \"NDPID\", \"NDPIQ\",\n","  \"PRE_VV\", \"PRE_VH\", \"PRE_NDPI\", \"POST_VV\", \"POST_VH\", \"POST_NDPI\"\n","]\n","\n","# GD paths.\n","classifierIdentifier = \"random_forest\"\n","destinationPath = \"...\""]},{"cell_type":"markdown","metadata":{"id":"BqXlmU2B2YA2"},"source":["# **5) Configuration**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QRit9LSfMf8A"},"outputs":[],"source":["featureAbbreviations = {\n","  \"VHVHD\": \"F1\",\n","  \"VHVHQ\": \"F2\",\n","  \"VVVHD\": \"F3\",\n","  \"VVVHQ\": \"F4\",\n","  \"VVVVD\": \"F5\",\n","  \"VVVVQ\": \"F6\",\n","  \"NDPID\": \"F7\",\n","  \"NDPIQ\": \"F8\",\n","  \"PRE_VH\": \"F9\",\n","  \"PRE_VV\": \"F10\",\n","  \"PRE_NDPI\": \"F11\",\n","  \"POST_VH\": \"F12\",\n","  \"POST_VV\": \"F13\",\n","  \"POST_NDPI\": \"F14\"\n","}"]},{"cell_type":"markdown","metadata":{"id":"WVCsEuw5NKzO"},"source":["# **6) Data Processing**"]},{"cell_type":"markdown","metadata":{"id":"NETxqn3098at"},"source":["Process the samples catalog."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xp1TmMFoTsCl"},"outputs":[],"source":["floodSamples = ee.List([])\n","nonWaterSamples = ee.List([])\n","waterSamples = ee.List([])\n","\n","for identifier in nonWaterSampleIdentifiers:\n","  nonWaterSamples = nonWaterSamples.add(ee.FeatureCollection(identifier))\n","\n","for identifier in floodSampleIdentifiers:\n","  floodSamples = floodSamples.add(ee.FeatureCollection(identifier))\n","\n","for identifier in waterSampleIdentifiers:\n","  waterSamples = waterSamples.add(ee.FeatureCollection(identifier))\n","\n","# Flatten sample collections.\n","floodSamples = ee.FeatureCollection(floodSamples).flatten()\n","nonWaterSamples = ee.FeatureCollection(nonWaterSamples).flatten()\n","waterSamples = ee.FeatureCollection(waterSamples).flatten()\n","\n","# Merge sample collections.\n","samples = floodSamples.merge(nonWaterSamples).merge(waterSamples)"]},{"cell_type":"markdown","metadata":{"id":"SuaP6NNBxhwE"},"source":["Create, train and process a RF classifier."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4366,"status":"ok","timestamp":1699862764229,"user":{"displayName":"lazaros stam","userId":"13443305908766428871"},"user_tz":-120},"id":"O8FqKA187Vqh","outputId":"2229bc7d-9173-4469-e32b-0471f27a30e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing classifier: `F2_F3_F4_F5_F6_F7_F8_F9_F10_F11_F12_F13_F14`.\n","Classifier contains `50` out of `50` trees.\n"]}],"source":["# Generate classifier name from feature abbreviations.\n","abbreviatedFeatures = [featureAbbreviations[key] for key in classifierFeatures]\n","abbreviatedFeatures = sorted(abbreviatedFeatures, key=lambda x: int(x[1:]))\n","abbreviation = \"_\".join(abbreviatedFeatures)\n","\n","print(f\"Processing classifier: `{abbreviation}`.\")\n","\n","classifier = ee.Classifier.smileRandomForest(**classifierParameters)  \\\n","  .train(**{\n","    \"features\": samples,\n","    \"classProperty\": \"class\",\n","    \"inputProperties\": classifierFeatures\n","  })\n","\n","# Assess classifier reliability.\n","classifierExplanation = classifier.explain()\n","\n","trees = ee.List(ee.Dictionary(classifierExplanation).get(\"trees\"))\n","expectedTreesCount = classifierParameters[\"numberOfTrees\"]\n","actualTreesCount = trees.size().getInfo()\n","\n","print(f\"Classifier contains `{actualTreesCount}` out of `{expectedTreesCount}` trees.\")\n","\n","if actualTreesCount < expectedTreesCount:\n","  raise KeyboardInterrupt\n","\n","# Determine tree sizes by evaluating the length of their string representations.\n","if actualTreesCount == expectedTreesCount:\n","  treeSizes = trees.map(lambda tree: ee.String(tree).length())\n","\n","# Calculate feature importances.\n","\n","# Absolute\n","absoluteFeatureImportances = ee.Dictionary(classifierExplanation.get(\"importance\"))\n","featureNames = absoluteFeatureImportances.keys()\n","\n","# Relative\n","importancesSum = absoluteFeatureImportances.values().reduce(ee.Reducer.sum())\n","relativeFeatureImportances = absoluteFeatureImportances.map(relative_property_importance)\n","\n","# Store classifier as a feature collection.\n","\n","# Handle the `Unable to export features with empty geometry` error.\n","dummyFeature = ee.Feature(ee.Geometry.Point([0, 0]))\n","dummyFeatures = ee.FeatureCollection(trees.map(lambda tree: dummyFeature.set(\"tree\", tree)))\n","\n","# Set properties.\n","\n","# Confusion matrix.\n","confusionMatrix = \"|\".join([\",\".join(map(str, sublist)) for sublist in classifier.confusionMatrix().getInfo()])\n","dummyFeatures = dummyFeatures.set(\"confusion_matrix\", confusionMatrix)\n","\n","# Feature names & importances.\n","featureImportances = \"|\".join([f\"{key},{value}\" for key, value in relativeFeatureImportances.getInfo().items()])\n","dummyFeatures = dummyFeatures.set(\"feature_importances\", featureImportances)\n","dummyFeatures = dummyFeatures.set(\"feature_names\", \",\".join(classifierFeatures))"]},{"cell_type":"markdown","metadata":{"id":"YA2wqqWaQQeE"},"source":["# **7) Console**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6121,"status":"ok","timestamp":1699862770341,"user":{"displayName":"lazaros stam","userId":"13443305908766428871"},"user_tz":-120},"id":"M7VYgpTrWz_q","outputId":"9e459dd0-0f8f-46ca-c912-083ed09453dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["*samples*\n","total number of samples: 225000\n","number of flood samples: 75000\n","number of water (sea) samples: 75000\n","number of non-water samples: 75000\n","\n","*classifier*\n","classifier-abbreviation: `F2_F3_F4_F5_F6_F7_F8_F9_F10_F11_F12_F13_F14`.\n","classifier-features: `['VHVHD', 'VHVHQ', 'VVVHD', 'VVVHQ', 'VVVVD', 'VVVVQ', 'NDPID', 'PRE_VV', 'PRE_VH', 'PRE_NDPI', 'POST_VV', 'POST_VH', 'POST_NDPI']`.\n","classifier tree sizes: `[322721, 326305, 314879, 305622, 309807, 309215, 332150, 319626, 325815, 322073, 313266, 315103, 319304, 329339, 305631, 329190, 314412, 310882, 326310, 319806, 311475, 319037, 326569, 314697, 326453, 316755, 323659, 325181, 317013, 326596, 321691, 316132, 320172, 317106, 315389, 315134, 330107, 315609, 319542, 314647, 323446, 312144, 331321, 320909, 313627, 338472, 326483, 316978, 329374, 311134]`.\n"]}],"source":["print(\"*samples*\");\n","print(f\"total number of samples:\", samples.size().getInfo())\n","print(f\"number of flood samples:\", floodSamples.size().getInfo())\n","print(f\"number of water (sea) samples:\", waterSamples.size().getInfo())\n","print(f\"number of non-water samples:\", nonWaterSamples.size().getInfo())\n","\n","print(\"\")\n","\n","print(\"*classifier*\")\n","print(f\"classifier-abbreviation: `{abbreviation}`.\")\n","print(f\"classifier-features: `{classifierFeatures}`.\")\n","print(f\"classifier tree sizes: `{treeSizes.getInfo()}`.\")"]},{"cell_type":"markdown","metadata":{"id":"VDXAfnmRQSZA"},"source":["# **8) Data Export**"]},{"cell_type":"markdown","metadata":{"id":"0kFDBMlI8fKT"},"source":["Submit tasks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HageTlvUW5Xa"},"outputs":[],"source":["exportTask = ee.batch.Export.table.toAsset(**{\n","  \"collection\": dummyFeatures,\n","  \"description\": classifierIdentifier,\n","  \"assetId\": os.path.join(destinationPath, classifierIdentifier),\n","})\n","\n","exportTask.start()"]},{"cell_type":"markdown","metadata":{"id":"7NrxzwkB8fNQ"},"source":["Monitor tasks."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3528,"status":"ok","timestamp":1699862839728,"user":{"displayName":"lazaros stam","userId":"13443305908766428871"},"user_tz":-120},"id":"hRyc_rNUIBKo","outputId":"cfa28126-a5bd-47f8-f71b-24ba59e1cfa3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Task_Id                   Task_State    Task_Type          Task_Attempt  Task_Description      Queue_Time    Execution_Time    Completion_Time  Error_Message\n","WOXQG7OWM5HZMMG7IBJKY4IY  COMPLETED     EXPORT_FEATURES               1  base_slope                 4.877            39.598             44.475\n"]}],"source":["export_tasks_viewer([exportTask.id])"]},{"cell_type":"markdown","metadata":{"id":"UUFF6jGGRwcw"},"source":["-End of Notebook-"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN3UrS5xoDDJ189uDiwL8S9","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
