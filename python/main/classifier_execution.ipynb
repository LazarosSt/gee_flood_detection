{"cells":[{"cell_type":"markdown","metadata":{"id":"5oeEOfZWPFsB"},"source":["# **1) Import the Modules**\n","\n","Modules are code libraries that contain a set of ready-to-use functions.\n","\n","* The `ee` module allows developers to interact with Google Earth Engine using the Python programming language.\n","* The `os` module provides functions to perform tasks such as file and directory operations, process management, and environment variable manipulation.\n","* The `json` module allows developers to load, read and write JSON files.\n","* The `yaml` module allows developers to load, read and write YAML files.\n","* The `sys` module contains methods and variables for modifying many elements of the Python runtime environment.\n","* The `tabulate` module allows the user to display data in a table format.\n","* The `google.colab` module provides access to some of the unique features and functionality of Google Colab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Jj6RgL0GcmR"},"outputs":[],"source":["import ee\n","import os\n","import json\n","import math\n","import yaml\n","import datetime\n","import tabulate\n","\n","from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"lGa1REK31H2j"},"source":["# **2) Authentication Procedure**\n","\n","This section provides instructions for setting up the Google Earth Engine Python API on Colab and for setting up Google Drive on Colab. These steps should be performed each time you start/restart/rollback a Colab session."]},{"cell_type":"markdown","metadata":{"id":"M1dE1vTqTaq7"},"source":["## **2.1) GEE**\n","\n","The `ee.Authenticate` function authenticates access to the Google Earth Engine servers, while the `ee.Initialize` function initializes it. After executing the following cell, the user is prompted to grant Google Earth Engine access to their Google account.\n","\n","**Note:** The Earth Engine API is installed by default in Google Colaboratory."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26604,"status":"ok","timestamp":1699863020476,"user":{"displayName":"lazaros stam","userId":"13443305908766428871"},"user_tz":-120},"id":"bJFUmXltHtWy","outputId":"cc94c74c-77a0-4222-c1d1-144248c1c69c"},"outputs":[{"output_type":"stream","name":"stdout","text":["To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n","\n","    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=-o_7Qxd5sqGOFBEaBJ1IuLliyssviIiu-fnxhQLVNSc&tc=p6wXQOt2JZFRf6p6mz5AArpVyajhOTmuLwOqxLw_uMo&cc=rLndFZsQFJpfNCSNmuoZN6LOO7-Af4TyYAqmmNGqXAE\n","\n","The authorization workflow will generate a code, which you should paste in the box below.\n","Enter verification code: 4/1AfJohXmoW7bF1QhSp51gxWTdVrEfrb5oAXRSh_h6Y57MRmsRahSwVuEiFNI\n","\n","Successfully saved authorization token.\n"]},{"output_type":"stream","name":"stderr","text":["*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_doiqkQG3NJ1t8IS?source=API\n"]}],"source":["ee.Authenticate()\n","ee.Initialize()"]},{"cell_type":"markdown","metadata":{"id":"k48w_jWcntia"},"source":["## **2.2) GD**\n","\n","The `drive.mount` function allows access to specific folders of Google Drive. Granting access to Google Drive allows code running in the notebook to modify files in Google Drive.\n","\n","**Note:** When using the `Mount Drive` button in the file browser, no authentication codes are required for notebooks edited only by the current user."]},{"cell_type":"code","source":["drive.mount(\"/content/gdrive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B-jZK-dxOpUb","executionInfo":{"status":"ok","timestamp":1699863040078,"user_tz":-120,"elapsed":18818,"user":{"displayName":"lazaros stam","userId":"13443305908766428871"}},"outputId":"b8f2b7bc-b6e4-4f4d-eabf-b2082ab0b1bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"GZBfbabwvRri"},"source":["# **3) Functions**"]},{"cell_type":"markdown","source":["Data Processing"],"metadata":{"id":"-u579MD6-lmJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_RxRbxIKRLZ"},"outputs":[],"source":["def power_to_db(raster):\n","  \"\"\"\n","  Description:\n","    Converts pixel values from power scale to dB scale.\n","\n","  Arguments:\n","    raster (ee.Image): The raster with pixel values in power scale.\n","\n","  Returns:\n","    The raster with pixel values in dB scale.\n","  \"\"\"\n","  return ee.Image(10).multiply(raster.log10())\n","\n","\n","def db_to_power(raster):\n","  \"\"\"\n","  Description:\n","    Converts pixel values from dB scale to power scale.\n","\n","  Args:\n","    raster (ee.Image): The raster with pixel values in dB scale.\n","\n","  Returns:\n","    The raster with pixel values in power scale.\n","  \"\"\"\n","  return ee.Image(10).pow(raster.divide(10))\n","\n","\n","def refined_lee(raster):\n","  \"\"\"\n","  Description:\n","    Applies the refined Lee speckle filter to an raster.\n","\n","  Arguments:\n","    raster (ee.Image): The raster to apply the filter on.\n","\n","  Returns:\n","    The filtered raster layer.\n","  \"\"\"\n","  def computations(b):\n","    img = raster.select([b])\n","\n","    # img must be in natural units, i.e. not in dB!\n","    # Set up 3x3 kernels\n","    weights3 = ee.List.repeat(ee.List.repeat(1,3),3)\n","    kernel3 = ee.Kernel.fixed(3,3, weights3, 1, 1, False)\n","\n","    mean3 = img.reduceNeighborhood(ee.Reducer.mean(), kernel3)\n","    variance3 = img.reduceNeighborhood(ee.Reducer.variance(), kernel3)\n","\n","    # Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions\n","    sample_weights = ee.List([[0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0], [0,1,0,1,0,1,0], [0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0]])\n","\n","    sample_kernel = ee.Kernel.fixed(7,7, sample_weights, 3,3, False)\n","\n","    # Calculate mean and variance for the sampled windows and store as 9 bands\n","    sample_mean = mean3.neighborhoodToBands(sample_kernel)\n","    sample_var = variance3.neighborhoodToBands(sample_kernel)\n","\n","    # Determine the 4 gradients for the sampled windows\n","    gradients = sample_mean.select(1).subtract(sample_mean.select(7)).abs()\n","    gradients = gradients.addBands(sample_mean.select(6).subtract(sample_mean.select(2)).abs())\n","    gradients = gradients.addBands(sample_mean.select(3).subtract(sample_mean.select(5)).abs())\n","    gradients = gradients.addBands(sample_mean.select(0).subtract(sample_mean.select(8)).abs())\n","\n","    # And find the maximum gradient amongst gradient bands\n","    max_gradient = gradients.reduce(ee.Reducer.max())\n","\n","    # Create a mask for band pixels that are the maximum gradient\n","    gradmask = gradients.eq(max_gradient)\n","\n","    # duplicate gradmask bands: each gradient represents 2 directions\n","    gradmask = gradmask.addBands(gradmask)\n","\n","    # Determine the 8 directions\n","    directions = sample_mean.select(1).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(7))).multiply(1)\n","    directions = directions.addBands(sample_mean.select(6).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(2))).multiply(2))\n","    directions = directions.addBands(sample_mean.select(3).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(5))).multiply(3))\n","    directions = directions.addBands(sample_mean.select(0).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(8))).multiply(4))\n","    # The next 4 are the not() of the previous 4\n","    directions = directions.addBands(directions.select(0).Not().multiply(5))\n","    directions = directions.addBands(directions.select(1).Not().multiply(6))\n","    directions = directions.addBands(directions.select(2).Not().multiply(7))\n","    directions = directions.addBands(directions.select(3).Not().multiply(8))\n","\n","    # Mask all values that are not 1-8\n","    directions = directions.updateMask(gradmask)\n","\n","    # \"collapse\" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked)\n","    directions = directions.reduce(ee.Reducer.sum())\n","\n","    sample_stats = sample_var.divide(sample_mean.multiply(sample_mean))\n","\n","    # Calculate localNoiseVariance\n","    sigmaV = sample_stats.toArray().arraySort().arraySlice(0,0,5).arrayReduce(ee.Reducer.mean(), [0])\n","\n","    # Set up the 7*7 kernels for directional statistics\n","    rect_weights = ee.List.repeat(ee.List.repeat(0,7),3).cat(ee.List.repeat(ee.List.repeat(1,7),4))\n","\n","    diag_weights = ee.List([[1,0,0,0,0,0,0], [1,1,0,0,0,0,0], [1,1,1,0,0,0,0], [1,1,1,1,0,0,0], [1,1,1,1,1,0,0], [1,1,1,1,1,1,0], [1,1,1,1,1,1,1]])\n","\n","    rect_kernel = ee.Kernel.fixed(7,7, rect_weights, 3, 3, False)\n","    diag_kernel = ee.Kernel.fixed(7,7, diag_weights, 3, 3, False)\n","\n","    # Create stacks for mean and variance using the original kernels. Mask with relevant direction.\n","    dir_mean = img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel).updateMask(directions.eq(1))\n","    dir_var = img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel).updateMask(directions.eq(1))\n","\n","    dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel).updateMask(directions.eq(2)))\n","    dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel).updateMask(directions.eq(2)))\n","\n","    # and add the bands for rotated kernels\n","    for i in range(1, 4):\n","      dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n","      dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n","      dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n","      dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n","\n","    # \"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked)\n","    dir_mean = dir_mean.reduce(ee.Reducer.sum())\n","    dir_var = dir_var.reduce(ee.Reducer.sum())\n","\n","    # A finally generate the filtered value\n","    varX = dir_var.subtract(dir_mean.multiply(dir_mean).multiply(sigmaV)).divide(sigmaV.add(1.0))\n","\n","    b = varX.divide(dir_var)\n","\n","    return dir_mean.add(b.multiply(img.subtract(dir_mean))) \\\n","      .arrayProject([0])                                    \\\n","      .arrayFlatten([[\"sum\"]])                              \\\n","      .float()\n","\n","  bandNames = raster.bandNames()\n","  raster = db_to_power(raster)\n","\n","  result = ee.ImageCollection(bandNames.map(computations)).toBands().rename(bandNames)\n","  return power_to_db(ee.Image(result))\n","\n","\n","def slope_correction(raster, dem):\n","  \"\"\"\n","  Description:\n","    Performs slope correction on the input raster using a digital elevation model (DEM).\n","\n","  Arguments:\n","    raster (ee.Image): The raster to perform slope correction on.\n","    dem (ee.Image): The digital elevation model used for correction.\n","\n","  Returns:\n","    The slope-corrected raster layer.\n","  \"\"\"\n","  # Obtain the geometry of the image.\n","  imgGeom = raster.geometry()\n","  # Clip the extent of the dem layer.\n","  srtm = ee.Image(dem).clip(imgGeom)\n","  # Convert pixel values from dB scale to linear scale.\n","  sigma0Pow = db_to_power(raster)\n","\n","  # 2.1.1 Radar geometry\n","  # Compute the mean aspect of the terrain over the region covered by the raster.\n","  theta_i = raster.select(\"angle\")\n","  phi_i = ee.Terrain.aspect(theta_i)                                        \\\n","    .reduceRegion(ee.Reducer.mean(), theta_i.get(\"system:footprint\"), 1000) \\\n","    .get(\"aspect\")\n","\n","  # 2.1.2 Terrain geometry\n","  # Calculate the slope and aspect of the terrain over the region covered by the raster.\n","  alpha_s = ee.Terrain.slope(srtm).select(\"slope\")\n","  phi_s = ee.Terrain.aspect(srtm).select(\"aspect\")\n","\n","  # 2.1.3 Model geometry\n","  # reduce to 3 angle\n","  phi_r = ee.Image.constant(phi_i).subtract(phi_s)\n","\n","  # Perform some mathematical conversions\n","  # (convert pixel values from degrees to radians).\n","  phi_rRad = phi_r.multiply(math.pi / 180)\n","  alpha_sRad = alpha_s.multiply(math.pi / 180)\n","  theta_iRad = theta_i.multiply(math.pi / 180)\n","  ninetyRad = ee.Image.constant(90).multiply(math.pi / 180)\n","\n","  # slope steepness in range (eq. 2)\n","  alpha_r = (alpha_sRad.tan().multiply(phi_rRad.cos())).atan()\n","\n","  # slope steepness in azimuth (eq 3)\n","  alpha_az = (alpha_sRad.tan().multiply(phi_rRad.sin())).atan()\n","\n","  # local incidence angle (eq. 4)\n","  theta_lia = (alpha_az.cos().multiply((theta_iRad.subtract(alpha_r)).cos())).acos()\n","  theta_liaDeg = theta_lia.multiply(180 / math.pi)\n","  # 2.2\n","  # Gamma_nought_flat\n","  gamma0 = sigma0Pow.divide(theta_iRad.cos())\n","  gamma0dB = ee.Image.constant(10).multiply(gamma0.log10())\n","  ratio_1 = gamma0dB.select(\"VV\").subtract(gamma0dB.select(\"VH\"))\n","\n","  # Volumetric Model\n","  nominator = (ninetyRad.subtract(theta_iRad).add(alpha_r)).tan()\n","  denominator = (ninetyRad.subtract(theta_iRad)).tan()\n","  volModel = (nominator.divide(denominator)).abs()\n","\n","  # apply model\n","  gamma0_Volume = gamma0.divide(volModel)\n","  gamma0_VolumeDB = ee.Image.constant(10).multiply(gamma0_Volume.log10())\n","\n","  # we add a layover/shadow maskto the original implmentation\n","  # layover, where slope > radar viewing angle\n","  alpha_rDeg = alpha_r.multiply(180 / math.pi)\n","  layover = alpha_rDeg.lt(theta_i)\n","\n","  # shadow where LIA > 90\n","  shadow = theta_liaDeg.lt(85)\n","\n","  # calculate the ratio for RGB vis\n","  ratio = gamma0_VolumeDB.select(\"VV\").subtract(gamma0_VolumeDB.select(\"VH\"))\n","\n","  output = gamma0_VolumeDB.addBands(ratio).addBands(alpha_r).addBands(phi_s).addBands(theta_iRad) \\\n","    .addBands(layover).addBands(shadow).addBands(gamma0dB).addBands(ratio_1)\n","\n","  return raster.addBands(\n","    output.select([\"VV\", \"VH\"], [\"VV\", \"VH\"]),\n","    None,\n","    True\n","  )\n","\n","\n","def export_tasks_viewer(exportTasksIds, tableFormat: str = \"plain\"):\n","  \"\"\"\n","  Description:\n","    Displays a table view which contains useful information about the provided export tasks.\n","\n","  Notes:\n","    * Task_Id: The task identifier.\n","    * Task_State: One of READY, RUNNING, COMPLETED, FAILED, CANCELLED, UNSUBMITTED or UNKNOWN.\n","    * Task_Type: One of EXPORT_IMAGE, EXPORT_TILES, EXPORT_FEATURES, EXPORT_VIDEO.\n","    * Task_Attempt: Number of attempts.\n","    * Task_Description: A human-readable description of the task.\n","    * Queue_Time: The time that is taken while being in a queue.\n","    * Execution_Time: The time spent by the servers executing the task.\n","    * Completion_Time: SUm of queue and execution times.\n","    * Error_Message: Failure reason. Appears only if state is FAILED. May also include other fields.\n","\n","  Arguments:\n","    exportTasksIdsList (list) (mandatory) A list of export task identifiers.\n","    tableFormat (str) (optional) The table format to use. Defaults to \"plain\".\n","\n","  Returns:\n","    None, displays the export tasks table.\n","  \"\"\"\n","  taskInfo = []\n","  tableHeaders = [\n","    \"Task_Id\", \"Task_State\", \"Task_Type\", \"Task_Attempt\", \"Task_Description\",\n","    \"Queue_Time\", \"Execution_Time\", \"Completion_Time\", \"Error_Message\"\n","  ]\n","  tableFormats = tabulate._table_formats.keys()\n","\n","  if tableFormat not in tableFormats:\n","    raise ValueError(f\"Invalid table format. Choose from: `{tableFormats}`.\")\n","\n","  # Populate taskInfo.\n","  for exportTaskId in exportTasksIds:\n","\n","    taskState = ee.data.getTaskStatus(exportTaskId)[0][\"state\"]\n","    taskType = ee.data.getTaskStatus(exportTaskId)[0][\"task_type\"]\n","    taskDescription = ee.data.getTaskStatus(exportTaskId)[0][\"description\"]\n","    startTimestamp = datetime.datetime.fromtimestamp(ee.data.getTaskStatus(exportTaskId)[0][\"start_timestamp_ms\"]/1000.0)\n","    updateTimestamp = datetime.datetime.fromtimestamp(ee.data.getTaskStatus(exportTaskId)[0][\"update_timestamp_ms\"]/1000.0)\n","    creationTimestamp = datetime.datetime.fromtimestamp(ee.data.getTaskStatus(exportTaskId)[0][\"creation_timestamp_ms\"]/1000.0)\n","\n","    queueTime = None\n","    taskAttempt = None\n","    executionTime = None\n","    completionTime = None\n","\n","    if taskState not in [\"READY\", \"RUNNING\"]:\n","      queueTime = (startTimestamp - creationTimestamp).total_seconds()\n","      executionTime = (updateTimestamp - startTimestamp).total_seconds()\n","\n","    if taskState == \"COMPLETED\":\n","      taskAttempt = ee.data.getTaskStatus(exportTaskId)[0][\"attempt\"]\n","      completionTime = (updateTimestamp - creationTimestamp).total_seconds()\n","\n","    try:\n","      errorMessage = ee.data.getTaskStatus(exportTaskId)[0][\"error_message\"]\n","    except KeyError:\n","      errorMessage = None  # This just means that the export task has not failed.\n","\n","    taskInfo.append([exportTaskId, taskState, taskType, taskAttempt, taskDescription, queueTime, executionTime, completionTime, errorMessage])\n","\n","  # Table display.\n","  table = tabulate.tabulate(taskInfo, headers=tableHeaders, tablefmt=tableFormat)\n","  print(table)"]},{"cell_type":"markdown","metadata":{"id":"jVJ6z_8Q9p2x"},"source":["# **4) Parameters**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QWM0FTA1McNB"},"outputs":[],"source":["# `Sentinel-1 GRD`\n","b1 = \"VV\"\n","vh = \"VH\"\n","\n","# `Digital Elevation Model`\n","demProvider = \"USGS\"\n","\n","# EMS case of interest\n","caseCode = \"emsr692\"\n","caseArea = \"magnesia\"\n","\n","# Projection of interest\n","projectionCRS = \"EPSG:4326\"\n","projectionScale = 10\n","\n","# `Classification`\n","rasterIdentifier = \"041299_04E8BD_E9C5_050224_060B99_D80F_slope\"\n","preEventRasterIdentifier = \"S1A_IW_GRDH_1SDV_20220103T162359_20220103T162424_041299_04E8BD_E9C5\"\n","postEventRasterIdentifier = \"S1A_IW_GRDH_1SDV_20230907T162412_20230907T162437_050224_060B99_D80F\"\n","\n","classifierIdentifier = \"users/stamlazaros/hua/t-h-e-s-i-s/assets/classifiers/base\"\n","classifierFeatures = [\n","  \"VHVHD\", \"VHVHQ\", \"VVVHD\", \"VVVHQ\", \"VVVVD\", \"VVVVQ\", \"NDPID\",\n","  \"PRE_VV\", \"PRE_VH\", \"PRE_NDPI\", \"POST_VV\", \"POST_VH\", \"POST_NDPI\"\n","]\n","\n","# GEE paths\n","destinationFolder = \"users/stamlazaros/hua/t-h-e-s-i-s/case_studies/emsr692/rasters/classified/2023_09_07\"\n","\n","# GD paths\n","# configFile = \"/content/gdrive/MyDrive/t-h-e-s-i-s/configurations/case_studies.json\"\n","configFile = \"/content/gdrive/MyDrive/t-h-e-s-i-s/configurations/case_studies.yaml\""]},{"cell_type":"markdown","metadata":{"id":"BqXlmU2B2YA2"},"source":["# **5) Configuration**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QRit9LSfMf8A"},"outputs":[],"source":["# `Digital Elevation Models`\n","demConfigs = {\n","  \"CGIAR\": {    # `SRTM Digital Elevation Data Version 4`\n","    \"name\": \"CGIAR/SRTM90_V4\"\n","  },\n","  \"NASA\": {     # `NASA NASADEM Digital Elevation`\n","    \"name\": \"NASA/NASADEM_HGT/001\"\n","  },\n","  \"USGS\": {     # `NASA SRTM Digital Elevation`\n","    \"name\": \"USGS/SRTMGL1_003\"\n","  },\n","  \"ASTER\": {    # AG100: ASTER Global Emissivity Dataset 100-meter V003`\n","    \"name\": \"NASA/ASTER_GED/AG100_003\"\n","  }\n","}\n","\n","# `Sentinel-1 GRD`\n","s1Config = {\n","  \"name\": \"COPERNICUS/S1_GRD\"\n","}\n","\n","bandCombinations = {\n","  \"sum\": {\n","    \"expression\": \"b1 + b2\",\n","    \"name\": \"b1b2S\"\n","  },\n","  \"difference\": {\n","    \"expression\": \"b1 - b2\",\n","    \"name\": \"b1b2D\"\n","  },\n","  \"product\": {\n","    \"expression\": \"b1 * b2\",\n","    \"name\": \"b1b2P\"\n","  },\n","  \"quotient\": {\n","    \"expression\": \"b1 / b2\",\n","    \"name\": \"b1b2Q\"\n","  },\n","  \"ndpi\": {\n","    \"expression\": \"(b1 - b2) / (b1 + b2)\",\n","    \"name\": \"NDPI\"\n","  }\n","}"]},{"cell_type":"code","source":["# Parse the appropriate configuration.\n","extension = os.path.splitext(configFile)[-1]\n","\n","try:\n","  with open(configFile, \"r\") as stream:\n","    # JSON\n","    if extension == \".json\":\n","      caseConfigs = json.load(stream)\n","    # YAML\n","    elif extension in (\".yaml\", \".yml\"):\n","      caseConfigs = yaml.safe_load(stream)\n","    else:\n","      raise ValueError(f\"Unsupported file format `{extension}`. Supported formats: `JSON`, `YAML`\")\n","\n","except FileNotFoundError as e:\n","  print(f\"Error: JSON file not found: {e}\")\n","\n","# GEE assets\n","demConfig = demConfigs[demProvider]\n","\n","caseConfig = caseConfigs[caseCode][caseArea]\n","caseConfig[\"area_of_interest\"] = ee.FeatureCollection(caseConfig[\"area_of_interest\"])"],"metadata":{"id":"gkQkNn3jvl6k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WVCsEuw5NKzO"},"source":["# **6) Data Processing**"]},{"cell_type":"markdown","source":["Define the projection of interest."],"metadata":{"id":"Uy0nD6L1_qwx"}},{"cell_type":"code","source":["projection = ee.Projection(projectionCRS).atScale(projectionScale)"],"metadata":{"id":"Dz1K_tq__q_I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load, filter and process raster collections."],"metadata":{"id":"gQdQbRAdxQwK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tgAkLMztHtcC"},"outputs":[],"source":["# `Digital Elevation Elevation`\n","elevation = ee.Image(demConfig[\"name\"]).unmask()\n","slope = ee.Terrain.slope(elevation)\n","\n","# `Sentinel-1 GRD`\n","preEventRaster = ee.Image(\"/\".join([s1Config[\"name\"], preEventRasterIdentifier]))\n","postEventRaster = ee.Image(\"/\".join([s1Config[\"name\"], postEventRasterIdentifier]))\n","\n","preEventRaster = preEventRaster.addBands(**{\n","  \"srcImg\": preEventRaster.select(\"angle\").updateMask(preEventRaster.select(\"angle\").mask().gt(0)),\n","  \"overwrite\": True,\n","})\n","\n","postEventRaster = postEventRaster.addBands(**{\n","  \"srcImg\": postEventRaster.select(\"angle\").updateMask(postEventRaster.select(\"angle\").mask().gt(0)),\n","  \"overwrite\": True,\n","})\n","\n","acquisition = postEventRaster.date()\n","eventDate = ee.Date(caseConfig[\"event_date\"])\n","\n","# Apply angular-based radiometric slope correction.\n","preEventRaster = slope_correction(preEventRaster, elevation)\n","postEventRaster = slope_correction(postEventRaster, elevation)\n","\n","# Apply a Refined-Lee speckle speckle noise filter.\n","preEventRaster = ee.Image(refined_lee(preEventRaster))    \\\n","  .select([\"VV\", \"VH\"])                                   \\\n","  .clipToCollection(caseConfig[\"area_of_interest\"])       \\\n","  .reproject(projection)\n","\n","postEventRaster = ee.Image(refined_lee(postEventRaster))  \\\n","  .select([\"VV\", \"VH\"])                                   \\\n","  .clipToCollection(caseConfig[\"area_of_interest\"])       \\\n","  .reproject(projection)"]},{"cell_type":"markdown","source":["Engineer new raster."],"metadata":{"id":"VG9sWaLkb3zH"}},{"cell_type":"code","source":["differenceExpression = bandCombinations[\"difference\"][\"expression\"]\n","quotientExpression = bandCombinations[\"quotient\"][\"expression\"]\n","ndpiExpression = bandCombinations[\"ndpi\"][\"expression\"]\n","\n","differenceName = bandCombinations[\"difference\"][\"name\"]\n","quotientName = bandCombinations[\"quotient\"][\"name\"]"],"metadata":{"id":"HAUZsnsOARiX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# `PRE_VVVHD`\n","prevvprevhDifference = ee.Image().expression(**{\n","    \"expression\": differenceExpression,\n","    \"opt_map\": {\n","      \"b1\": preEventRaster.select(b1),\n","      \"b2\": preEventRaster.select(vh)\n","    }\n","  })  \\\n","  .rename(differenceName.replace(\"b1\", b1).replace(\"b2\", vh))\n","\n","# `POST_VVVHD`\n","postvvpostvhDifference = ee.Image().expression(**{\n","    \"expression\": differenceExpression,\n","    \"opt_map\": {\n","      \"b1\": postEventRaster.select(b1),\n","      \"b2\": postEventRaster.select(vh)\n","    }\n","  })  \\\n","  .rename(differenceName.replace(\"b1\", b1).replace(\"b2\", vh))\n","\n","# `VVVVD`\n","postvvprevvDifference = ee.Image().expression(**{\n","    \"expression\": differenceExpression,\n","    \"opt_map\": {\n","      \"b1\": postEventRaster.select(b1),\n","      \"b2\": preEventRaster.select(b1)\n","    }\n","  })  \\\n","  .rename(differenceName.replace(\"b1\", b1).replace(\"b2\", b1))\n","\n","# `VHVHD`\n","postvhprevhDifference = ee.Image().expression(**{\n","    \"expression\": differenceExpression,\n","    \"opt_map\": {\n","      \"b1\": postEventRaster.select(vh),\n","      \"b2\": preEventRaster.select(vh)\n","    }\n","  })  \\\n","  .rename(differenceName.replace(\"b1\", vh).replace(\"b2\", vh))\n","\n","# `VVVHD`\n","postvvprevhDifference = ee.Image().expression(**{\n","    \"expression\": differenceExpression,\n","    \"opt_map\": {\n","      \"b1\": postEventRaster.select(b1),\n","      \"b2\": preEventRaster.select(vh)\n","    }\n","  })  \\\n","  .rename(differenceName.replace(\"b1\", b1).replace(\"b2\", vh))\n","\n","# `PRE_VVVHQ`\n","prevvprevhQuotient = ee.Image().expression(**{\n","    \"expression\": quotientExpression,\n","    \"opt_map\": {\n","      \"b1\": preEventRaster.select(b1),\n","      \"b2\": preEventRaster.select(vh)\n","    }\n","  })  \\\n","  .rename(quotientName.replace(\"b1\", b1).replace(\"b2\", vh))\n","\n","# `POST_VVVHQ`\n","postvvpostvhQuotient = ee.Image().expression(**{\n","    \"expression\": quotientExpression,\n","    \"opt_map\": {\n","      \"b1\": postEventRaster.select(b1),\n","      \"b2\": postEventRaster.select(vh)\n","    }\n","  })  \\\n","  .rename(quotientName.replace(\"b1\", b1).replace(\"b2\", vh))\n","\n","# `VVVVQ`\n","postvvprevvQuotient = ee.Image().expression(**{\n","    \"expression\": quotientExpression,\n","    \"opt_map\": {\n","      \"b1\": postEventRaster.select(b1),\n","      \"b2\": preEventRaster.select(b1)\n","    }\n","  })  \\\n","  .rename(quotientName.replace(\"b1\", b1).replace(\"b2\", b1))\n","\n","# `VHVHQ`\n","postvhprevhQuotient = ee.Image().expression(**{\n","    \"expression\": quotientExpression,\n","    \"opt_map\": {\n","      \"b1\": postEventRaster.select(vh),\n","      \"b2\": preEventRaster.select(vh)\n","    }\n","  })  \\\n","  .rename(quotientName.replace(\"b1\", vh).replace(\"b2\", vh))\n","\n","# `VVVHQ`\n","postvvprevhQuotient = ee.Image().expression(**{\n","    \"expression\": quotientExpression,\n","    \"opt_map\": {\n","      \"b1\": postEventRaster.select(b1),\n","      \"b2\": preEventRaster.select(vh)\n","    }\n","  })  \\\n","  .rename(quotientName.replace(\"b1\", b1).replace(\"b2\", vh))\n","\n","# `PRE_NDPI`\n","preNDPI = ee.Image().expression(**{\n","    \"expression\": ndpiExpression,\n","    \"opt_map\": {\n","      \"b1\": preEventRaster.select(b1),\n","      \"b2\": preEventRaster.select(vh)\n","    }\n","  })  \\\n","  .rename(\"PRE_NDPI\")\n","\n","# `POST_NDPI`\n","postNDPI = ee.Image().expression(**{\n","    \"expression\": ndpiExpression,\n","    \"opt_map\": {\n","      \"b1\": postEventRaster.select(b1),\n","      \"b2\": postEventRaster.select(vh)\n","    }\n","  })  \\\n","  .rename(\"POST_NDPI\")\n","\n","# `NDPID`\n","NDPIDifference = postNDPI.subtract(preNDPI).rename(\"NDPID\")\n","\n","# Rename S1-GRD raster bands using a regular expression.\n","preEventSamplesSource = preEventRaster.regexpRename(\"V\", \"PRE_V\", False)\n","postEventSamplesSource = postEventRaster.regexpRename(\"V\", \"POST_V\", False)\n","\n","# Add bands to both pre- & post- event rasters.\n","preEventRaster = preEventRaster.addBands([prevvprevhQuotient])\n","postEventRaster = postEventRaster.addBands([postvvpostvhQuotient])\n","\n","# Generate a composite with the essential bands for classification.\n","raster = preEventSamplesSource.addBands([\n","  postEventSamplesSource, postvvprevvDifference, postvhprevhDifference,\n","  postvvprevhDifference, postvvprevvQuotient, postvhprevhQuotient,\n","  postvvprevhQuotient, preNDPI, postNDPI, NDPIDifference,\n","])"],"metadata":{"id":"g9I6rdWiAznd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Raster classification"],"metadata":{"id":"kxJlXuVv9Vz7"}},{"cell_type":"code","source":["# Construct a RF classifier from the decision tree feature collection.\n","trees = ee.FeatureCollection(classifierIdentifier).aggregate_array(\"tree\")\n","classifier = ee.Classifier.decisionTreeEnsemble(trees)\n","\n","# Perform classification.\n","classified = raster.select(classifierFeatures).classify(classifier)"],"metadata":{"id":"kAOmdsI79WB0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b_hYOYWjBQZT"},"source":["# **7) Console**"]},{"cell_type":"code","source":["print(\"*dates*\")\n","print(f\"\\t event date: `{eventDate.format('YYYY-MM-DD').getInfo()}`\")\n","print(f\"\\t acquisition date: `{acquisition.format('YYYY-MM-DD').getInfo()}`\")\n","print(f\"\\t difference (in days): `{acquisition.difference(eventDate, 'days').getInfo()}`\")"],"metadata":{"id":"m_c6WATDRKYc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699866088644,"user_tz":-120,"elapsed":1265,"user":{"displayName":"lazaros stam","userId":"13443305908766428871"}},"outputId":"8f961d62-e4ec-405f-bf49-68a90e26b80c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["*dates*\n","\t event date: `2018-03-86`\n","\t acquisition date: `2023-09-250`\n","\t difference (in days): `1990.0584722222222`\n"]}]},{"cell_type":"markdown","source":["# **8) Export Tasks**"],"metadata":{"id":"Ry3do2eaL-Ac"}},{"cell_type":"markdown","source":["Submit tasks."],"metadata":{"id":"0kFDBMlI8fKT"}},{"cell_type":"code","source":["exportTask = ee.batch.Export.image.toAsset(**{\n","  \"description\": rasterIdentifier,\n","  \"maxPixels\": 1e13,\n","  \"image\": classified,\n","  \"scale\": projectionScale,\n","  \"crs\": projectionCRS,\n","  \"region\": caseConfig[\"area_of_interest\"].geometry(),\n","  \"assetId\": \"/\".join([destinationFolder, rasterIdentifier])\n","})\n","\n","exportTask.start()"],"metadata":{"id":"edkfasWsRKyB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Monitor tasks."],"metadata":{"id":"7NrxzwkB8fNQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mz41VSUbngw8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699867291786,"user_tz":-120,"elapsed":3524,"user":{"displayName":"lazaros stam","userId":"13443305908766428871"}},"outputId":"6f27bb15-ba6e-449c-bf24-854a487a16b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Task_Id                   Task_State    Task_Type       Task_Attempt  Task_Description                               Queue_Time    Execution_Time    Completion_Time  Error_Message\n","WPRTRDKCUBIIYWQ5X77EZ5ER  COMPLETED     EXPORT_IMAGE               1  041299_04E8BD_E9C5_050224_060B99_D80F_slope        13.503           925.756            939.259\n"]}],"source":["export_tasks_viewer([exportTask.id])"]},{"cell_type":"markdown","metadata":{"id":"UUFF6jGGRwcw"},"source":["-End of Notebook-"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1s7RYR5wJH9RlM9nQkFbr5-O87c9jij4-","authorship_tag":"ABX9TyPf6/dfmTOIpFa2H4b9q7fg"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}